<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introdução a Web Scraping com R</title>
    <meta charset="utf-8" />
    <meta name="author" content="Jodavid Ferreira" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link rel="stylesheet" href="css/jodavid.css" type="text/css" />
    <link rel="stylesheet" href="css/mmp.css" type="text/css" />
    <link rel="stylesheet" href="css/mmp-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Introdução a Web Scraping com R
### Jodavid Ferreira
### 03.02.2021

---

layout: true

&lt;div class="my-footer"&gt;&lt;span&gt;

&lt;a href="http://jodavid.github.io"&gt;Jodavid Ferreira&lt;/a&gt; - email: &lt;a href="mailto:jdaf1@de.ufpe.br"&gt;jdaf1@de.ufpe.br&lt;/a&gt;
&lt;/span&gt;&lt;/div&gt;


---





&lt;br/&gt;
# O que é Web Scraping?

&lt;br/&gt;
* O **Web Scraping** é uma área da **Text Mining (Mineração de Texto)** ;


&lt;br/&gt;&lt;br/&gt;
### O que é Mineração de Texto?

Segundo o Livro '`Text Mining in Practice with R`':

&lt;br/&gt;
*  "Mineração de texto é o processo de **destilar**&lt;sup&gt;1&lt;/sup&gt; **insights** de texto".


.footnote[
[1] A destilação é uma técnica de separação.
]

---

### Onde a mineração de texto se encaixa?

&lt;br/&gt;
* Para **acadêmicos**, pode auxiliar na compreensão de transcrições qualitativas ou num estudo da linguagem;

&lt;br/&gt;
* Para **empresas**, pode render informações interessantes que auxiliarão na modelagem preditiva por exemplo;

&lt;br/&gt;
* Aos **profissionais de marketing**, podem auxiliar na criação de textos, fornecendo recomendações precisas para sua organização.
&lt;!--isso porque através de análises de textos externos, eles podem criar os seus fornecendo recomendações precisas para sua organização.--&gt;

&lt;br/&gt;
* Então, a **mineração de texto** pode ser usada em qualquer decisão baseada em dados, onde o texto se encaixa naturalmente como uma entrada.


---

# Pacote `rvest`

&lt;br/&gt;
&lt;br/&gt;

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="https://raw.githubusercontent.com/tidyverse/rvest/master/man/figures/logo.png" alt="&amp;lt;center&amp;gt;&amp;lt;b&amp;gt;Logo - rvest &amp;lt;/center&amp;gt;&amp;lt;/b&amp;gt;" width="20%" /&gt;
&lt;p class="caption"&gt;&lt;center&gt;&lt;b&gt;Logo - rvest &lt;/center&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;br/&gt;


`rvest` ajuda você a extrair (ou colher) dados de páginas da web.

Ele foi projetado para funcionar com *magrittr* (pacote responsável pelo operador pipe *%&gt;%*) para facilitar a expressão de tarefas comuns de web scraping, inspiradas em bibliotecas como a `beautiful soup` e `RoboBrowser`.

&lt;!--
Se você estiver copiando várias páginas, recomendo fortemente o uso de rvest em conjunto com educado. O pacote educado garante que você respeite o robots.txt e não martele o site com muitas solicitações.
--&gt;

---

# O que é HTML e CSS ?

* **HTML** (HyperText Markup Language - Linguagem de Marcação de Hipertexto) - é uma linguagem de marcação usada para estruturar uma página web.

* **CSS** (Cascading Style Sheets - Folha de Estilo em Cascata) - é usado para estilizar os elementos escritos no *HTML*.



### O que precisa saber ?

Em **HTML** e **CSS**, existe a possibilidade de aplicar estilos através de 'class' e 'id';



* **HTML** : 
 * *class* : é o atributo global formado por uma lista das classes de um elemento, separada por espaços.
&lt;!-- Classes permitem a CSS e Javascript selecionar e acessar elementos específicos através dos seletores de classe ou funções como o método DOM. --&gt;
  * *id* : define um identificador exclusivo (ID) que deve ser único por todo o documento.
&lt;!--Seu objetivo é identificar o elemento ao navegar por âncoras (usando um identificador de fragmento), quando utilizar scripts ou estilizando (com CSS).--&gt;

* **CSS**: usado para personalizar a parte visual dos sites.

---

# Instalando o `rvest`

&lt;br/&gt;
Instalando o `rvest` através do `devtools`

&lt;br/&gt;

```r
install.packages("devtools")
library(devtools)
devtools::install_github("tidyverse/rvest")
```

&lt;br/&gt;
&lt;br/&gt;
Lendo o pacote:

&lt;br/&gt;

```r
library(rvest)
```

---

## Exemplo 1: Extraindo informações site Jarbas

### Projeto Serenata de Amor

O estudo será realizado sobre o projeto “SERENATA DE AMOR” [https://serenata.ai/](https://serenata.ai/), que é um projeto aberto no qual usa data science (ciência de dados) - a mesma tecnolgia usada por gigantes como Google, Facebook e Netflix - com o objetivo de monitorar os gastos públicos e compartilhar informações de forma acessível a todos.


* Jarbas - [https://jarbas.serenata.ai/dashboard/chamber_of_deputies/reimbursement/](https://jarbas.serenata.ai/dashboard/chamber_of_deputies/reimbursement/)


&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="imagens/jarbas.png" alt="&amp;lt;center&amp;gt;&amp;lt;b&amp;gt;site Jarbas &amp;lt;/center&amp;gt;&amp;lt;/b&amp;gt;" width="100%" /&gt;
&lt;p class="caption"&gt;&lt;center&gt;&lt;b&gt;site Jarbas &lt;/center&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/div&gt;



---

## Exemplo 1: Extraindo informações site Jarbas

### Passo 1: Lendo a URL

Usando a função `read_html` do pacote `xml2` (este pacote é uma dependência do `rvest`) para ler a url.


```r
library(rvest)

url &lt;- "https://jarbas.serenata.ai/dashboard/chamber_of_deputies/reimbursement/"
jarbas_webpage &lt;- read_html(url)
```

---


## Exemplo 1: Extraindo informações site Jarbas

### Passo 2: Extrair dados de classes do CSS

Class: *.field-congressperson_name*

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="imagens/field-congresso-name.png" alt="&amp;lt;center&amp;gt;&amp;lt;b&amp;gt;class:  .field-congressperson_name &amp;lt;/center&amp;gt;&amp;lt;/b&amp;gt;" width="100%" /&gt;
&lt;p class="caption"&gt;&lt;center&gt;&lt;b&gt;class:  .field-congressperson_name &lt;/center&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/div&gt;

---


## Exemplo 1: Extraindo informações site Jarbas

### Passo 2:


Duas funções serão utilizadas aqui:

1. *html_nodes*: Use esta função para extrair os nós que desejamos (neste caso nós com ".field-congressperson_name" como classe css)
2. *html_text*: Use esta função para extrair o texto entre dos nós html (neste caso, os nomes de nossos representantes)


```r
#Scraping  usando classe css ‘field-congressperson_name’
jarbas_names_html &lt;-html_nodes(jarbas_webpage, '.field-congressperson_name')
jarbas_names &lt;- html_text(jarbas_names_html)
head(jarbas_names,3)
```

```
## [1] "Valmir Assunção" "Hélio Leite"     "Hélio Leite"
```

---

## Exemplo 1: Extraindo informações site Jarbas

### Passo 2:



```r
#SUBQUOTA TRANSLATED
jarbas_subquota_html &lt;-html_nodes(jarbas_webpage, '.field-subquota_translated')
jarbas_subquota &lt;- html_text(jarbas_subquota_html)
head(jarbas_subquota,3)
```

```
## [1] "Combustíveis e lubrificantes"        "Divulgação da atividade parlamentar" "Divulgação da atividade parlamentar"
```

```r
#Fornecedor
jarbas_provider_html &lt;-html_nodes(jarbas_webpage, '.field-supplier_info')
jarbas_provider &lt;- html_text(jarbas_provider_html)
head(jarbas_provider,3)
```

```
## [1] "POSTO MK 107 NORTE LTDA05.625.571/0001-35"                         "PRISCILLA DE CASSIA PORTELA VINHOTE 7054665724934.314.072/0001-25" "M SANTOS GUIMARAES EIRELI23.936.281/0001-94"
```

```r
#Valores em Real
jarbas_value_html &lt;-html_nodes(jarbas_webpage, '.field-value')
jarbas_value &lt;- html_text(jarbas_value_html)
head(jarbas_value,3)
```

```
## [1] "R$ 198,84" "R$ 900,00" "R$ 300,00"
```

---

## Exemplo 1: Extraindo informações site Jarbas

### Passo 2:

A seguir serão mostrados o valor do reembolso, eles são extraídos
em tipo de variável caracter: Ex: R\$ 139,76, R\$ 40,23.
Entretanto, como desejamos manipular esses números, precisamos convertê-los para tipo de variável numérica, dessa forma será utilizado a biblioteca: "*stringr*" mais especificamente a função: `str_extract`. Segue o script para conversão da variável.


```r
library(stringr)
#Conversão para tipo numérico
jarbas_value &lt;- as.numeric(sub(",",".",
                str_extract(jarbas_value,pattern = "\\-*\\d+,\\s{0,}\\d+")))
head(jarbas_value,3)
```

```
## [1] 198.84 900.00 300.00
```

---

## Exemplo 1: Extraindo informações site Jarbas

### Passo 3: Geração de data.frame


```r
#Combinando todas as características obtidas
jarbas_names &lt;- str_extract(jarbas_names,pattern = boundary("word"))
jarbas_df &lt;- data.frame(
  Name = jarbas_names,
  Subquota = jarbas_subquota,
  Provider = jarbas_provider,
  Value = jarbas_value
  )

#Mostrando tipo das variáveis
str(jarbas_df)
```

```
## 'data.frame':	100 obs. of  4 variables:
##  $ Name    : chr  "Valmir" "Hélio" "Hélio" "Hélio" ...
##  $ Subquota: chr  "Combustíveis e lubrificantes" "Divulgação da atividade parlamentar" "Divulgação da atividade parlamentar" "Combustíveis e lubrificantes" ...
##  $ Provider: chr  "POSTO MK 107 NORTE LTDA05.625.571/0001-35" "PRISCILLA DE CASSIA PORTELA VINHOTE 7054665724934.314.072/0001-25" "M SANTOS GUIMARAES EIRELI23.936.281/0001-94" "SUPER POSTO PALMEIRA LTDA83.838.839/0001-20" ...
##  $ Value   : num  199 900 300 5022 13000 ...
```

---

## Exemplo 1: Extraindo informações site Jarbas

### Passo 4: Geração de um gráfico

Foram utilizados as 50 primeiras linhas do data.frame e uma biblioteca *ggplot2* para geração do gráfico.


```r
library(ggplot2)

jarbas_df &lt;- jarbas_df[1:50,]

ggplot(
  jarbas_df, aes(Value,Name,colour=Subquota)) +
  geom_point() +
  labs(title="", x ="pedidos de reembolso (R$)",
       y = "deputados",colour="SUBQUOTA TRANSLATED")
```


---

&lt;img src="index_files/figure-html/unnamed-chunk-12-1.png" style="display: block; margin: auto;" /&gt;

---

## Exemplo 2: Texto de um WebSite

Neste segundo exemplo vamos obter o texto de um site e analisá-lo.


* Site El País (categoria de Tecnologia) - [https://brasil.elpais.com/brasil/2021-01-26/todos-os-brasileiros-estao-com-seus-dados-a-venda-e-ha-muito-pouco-o-que-se-pode-fazer-para-se-proteger.html](https://brasil.elpais.com/brasil/2021-01-26/todos-os-brasileiros-estao-com-seus-dados-a-venda-e-ha-muito-pouco-o-que-se-pode-fazer-para-se-proteger.html)


&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="imagens/elpais.png" alt="&amp;lt;center&amp;gt;&amp;lt;b&amp;gt;site ElPaís &amp;lt;/center&amp;gt;&amp;lt;/b&amp;gt;" width="100%" /&gt;
&lt;p class="caption"&gt;&lt;center&gt;&lt;b&gt;site ElPaís &lt;/center&gt;&lt;/b&gt;&lt;/p&gt;
&lt;/div&gt;

---

## Exemplo 2: Texto de Site

### Passo 1: Lendo a URL


```r
library(rvest)

url &lt;- "https://brasil.elpais.com/brasil/2021-01-26/todos-os-brasileiros-estao-com-seus-dados-a-venda-e-ha-muito-pouco-o-que-se-pode-fazer-para-se-proteger.html"
webpage &lt;- read_html(url)
```


### Passo 2: Extraindo texto de Site
  

```r
# Passo 2:
#Scraping  usando ‘p’
names_html &lt;-html_nodes(webpage, 'p')
names &lt;- html_text(names_html)
head(names)
```

```
## [1] "Este navegador não é mais compatível. Para visitar EL PAÍS com a melhor experiência, atualize-o para a versão mais recente ou baixe um dos seguintes navegadores compatíveis:"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             "Um megavazamento de dados pessoais de 223 milhões de brasileiros tornado público na semana passada pela empresa de segurança digital PSafe pode ser o maior na história do país e tem tudo para ser a primeira prova de fogo da Autoridade Nacional de Proteção de Dados (ANPD), criada a partir da entrada em vigor da Lei Geral de Proteção de Dados (LGPD) em agosto do ano passado. Também é o primeiro incidente desta magnitude que se tem notícia no Brasil. A lista com milhões de nomes completos, CPFs e datas de nascimento —de pessoas vivas e mortas— estava disponível para download gratuito a partir de um fórum de discussão na deep web —cópias do arquivo original foram feitas e podiam ser encontradas por qualquer um a partir de buscadores de internet. Em troca de bitcoins, o perfil anônimo responsável pelo vazamento dizia ser possível obter ainda retratos, endereço, telefone, declaração do Imposto de Renda, listas de familiares, renda mensal, score de crédito e muito mais dos alvos em questão. Na terça-feira, após a repercussão do caso, o material foi retirado do ar no fórum de livre acesso com qualquer navegador, mas continua em negociação na deep web." "Na lista há dados de gente famosa e autoridades públicas. De acordo com a PSafe, cibercriminosos também tiveram acesso a informações detalhadas sobre mais de 104 milhões de veículos e dados sigilosos de 40 milhões de empresas."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        "“O vazamento é real, confirmada a autenticidade de todos os dados, é o maior vazamento da história do Brasil e certamente um dos maiores do mundo”, afirma Marco DeMello, CEO da PSafe. “Estávamos monitorando a deep web para alguns de nossos clientes e nos deparamos com milhões de CPNJs em negociação, rastreamos e chegamos na fonte”, diz. Ele afirma que a equipe de segurança da empresa entrou em contato com o hacker, que disse cobrar 100 dólares por pacotes com os registros de mil pessoas, empresas ou veículos. Ele diz não ser brasileiro e que vai vender no máximo 1 milhão de contatos para cada comprador, pois pretende ganhar dinheiro com essa base de dados por muito tempo ainda. Segundo DeMello, nas conversas o hacker diz que roubou a base dados da Serasa/Experian, empresa de análise de crédito que cria perfis dos consumidores brasileiros entre outras atividades, mas não tem como saber se isso é verdade. A mesma alegação aparece na página onde ele vende o material, assim como no nome de alguns arquivos."                                                                                                                                                
## [5] "Apoie a produção de notícias como esta. Assine o EL PAÍS por 30 dias por 1 US$"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            "Procurada pela reportagem através de sua assessoria de imprensa, a Serasa/Experian respondeu, após a publicação, que a empresa não é a fonte dos dados vazados. “Embora o hacker afirme que parte dos dados veio da Serasa, com base em nossa análise detalhada até este ponto, concluímos que a Serasa não é a fonte”, diz a nota enviada. “Também não vemos evidências de que nossos sistemas tenham sido comprometidos”, afirma a empresa, que ainda diz não possuir todos os dados oferecidos na internet e que está em contato com autoridades reguladoras para ajudar no caso. "
```

---

## Exemplo 2: Texto de Site
  
### Passo 3: Preparação dos dados

Organizando os dados para geração do gráfico da Nuvem de Tags

* `Corpus`: função que transforma vetores/listas em coleções de documentos que contêm texto.


```r
# Convertendo a lista em vetor
dados_str &lt;- unlist(names)

# Início do código para Nuvem de palavras
library(tm)

texto &lt;- tolower(dados_str) # Colocando as palavras em minusculos
lista_palavras &lt;- strsplit(texto, "\\W+") # dividindo o texto nas palavras
vetor_palavras &lt;- Corpus(VectorSource(unlist(lista_palavras))) #Convertendo em formato Corpus
```

---
    
### Passo 4: Geração de um gráfico de Nuvem de Tags
  
Foram utilizados o data.frame e uma biblioteca *ggplot2* para geração do gráfico.


```r
library(wordcloud)
library(yarrr)

wordcloud(words = vetor_palavras, min.freq = 3, random.order = TRUE,
          colors = yarrr::piratepal("basel"), use.r.layout = TRUE, rot.per = 0.5)
```

---

## Nuvem de Tags

&lt;img src="index_files/figure-html/unnamed-chunk-18-1.png" style="display: block; margin: auto;" /&gt;

---
    
## Extra: Frequência das palavras


```r
vetor &lt;- Corpus(VectorSource(texto))
myTable &lt;- TermDocumentMatrix(vetor)
myTable
```

```
## &lt;&lt;TermDocumentMatrix (terms: 547, documents: 13)&gt;&gt;
## Non-/sparse entries: 768/6343
## Sparsity           : 89%
## Maximal term length: 16
## Weighting          : term frequency (tf)
```




```r
#Convertendo em Matriz
matriz_palavras &lt;- as.matrix(myTable)
matriz_palavras[1:5,]
```

```
##               Docs
## Terms          1 2 3 4 5 6 7 8 9 10 11 12 13
##   atualize-o   1 0 0 0 0 0 0 0 0  0  0  0  0
##   baixe        1 0 0 0 0 0 0 0 0  0  0  0  0
##   com          1 2 1 4 0 2 1 1 3  1  1  0  0
##   compatíveis: 1 0 0 0 0 0 0 0 0  0  0  0  0
##   compatível.  1 0 0 0 0 0 0 0 0  0  0  0  0
```


---

## Extra: Frequência das palavras


```r
# Ordenando por frequência
matriz_palavras &lt;- sort(rowSums(matriz_palavras), decreasing = TRUE)
dataframe_palavras &lt;- data.frame(palavras = names(matriz_palavras),
                                 frequencia = matriz_palavras, row.names = NULL)

head(dataframe_palavras,18)
```

```
##     palavras frequencia
## 1        que         25
## 2      dados         20
## 3        com         17
## 4       para         16
## 5        ser         13
## 6        não         12
## 7        dos         10
## 8        por         10
## 9        diz          7
## 10   milhões          6
## 11      como          6
## 12       uma          6
## 13   empresa          5
## 14      pela          5
## 15 vazamento          5
## 16     todos          5
## 17       até          5
## 18      mais          4
```


---


# Fontes

* Slide produzido com Rmarkdown, com template
`Xaringan`: [https://github.com/yihui/xaringan](https://github.com/yihui/xaringan).
* Livro: `Text Mining in Practice with R`;

* [https://github.com/tidyverse/rvest](https://github.com/tidyverse/rvest)

* [https://brasil.elpais.com/brasil/2021-01-26/todos-os-brasileiros-estao-com-seus-dados-a-venda-e-ha-muito-pouco-o-que-se-pode-fazer-para-se-proteger.html](https://brasil.elpais.com/brasil/2021-01-26/todos-os-brasileiros-estao-com-seus-dados-a-venda-e-ha-muito-pouco-o-que-se-pode-fazer-para-se-proteger.html)
webpage &lt;- read_html(url)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
